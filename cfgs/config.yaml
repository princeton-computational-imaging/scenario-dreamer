scratch_root: ${oc.env:SCRATCH_ROOT} # scratch root directory, used for datasets and checkpoints
dataset_root: ${oc.env:DATASET_ROOT} # root directory for datasets
project_root: ${oc.env:PROJECT_ROOT} # project root directory
waymo_data_folder: ${dataset_root}/waymo_open_dataset_motion_v_1_1_0 # path to the Waymo Open Dataset
waymo_train_folder: ${waymo_data_folder}/training # path to the training set of the Waymo Open Dataset
waymo_val_folder: ${waymo_data_folder}/validation # path to the validation set of the Waymo Open Dataset
waymo_test_folder: ${waymo_data_folder}/testing # path to the testing set of the Waymo Open Dataset

hydra:
  run:
    dir: ${project_root}/slurm_logs/${now:%Y.%m.%d}/${now:%H.%M.%S}/${hydra.job.override_dirname}

generate_waymo_dataset:
  output_data_folder_train: ${dataset_root}/scenario_dreamer_waymo/train # output folder for training data
  output_data_folder_val: ${dataset_root}/scenario_dreamer_waymo/val # output folder for validation data
  output_data_folder_test: ${dataset_root}/scenario_dreamer_waymo/test # output folder for test data
  num_workers: 20 # number of workers to use for generating the dataset
  mode: train # or val or test
  chunk_idx: -1 # If chunk_idx >= 0, indexes into the chunk_idx'th chunk of size chunk_size. If chunk_idx=-1, process all chunks in parallel processes
  chunk_size: 50 # size of each chunk to process in parallel processes, if chunk_idx >= 0

preprocess_waymo:
  stage: scenario_dreamer # or ctrl_sim
  num_workers: 10 # number of workers to use for preprocessing the dataset
  mode: train # or val or test
  chunk_idx: -1 # If chunk_idx >= 0, indexes into the chunk_idx'th chunk of size chunk_size. If chunk_idx=-1, process all chunks in parallel processes
  chunk_size: 50000 # size of each chunk to process in parallel processes, if chunk_idx >= 0

preprocess_nuplan:
  num_workers: 10 # number of workers to use for preprocessing the dataset
  mode: train # or val or test
  chunk_idx: -1 # If chunk_idx >= 0, indexes into the chunk_idx'th chunk of size chunk_size. If chunk_idx=-1, process all chunks in parallel processes
  chunk_size: 50000 # size of each chunk to process in parallel processes, if chunk_idx >= 0

postprocess_sim_envs:
  run_name: scenario_dreamer_ldm_large_${dataset_name.name} # run name of ldm that generated the simulation environments
  pre_path: ${scratch_root}/checkpoints/${postprocess_sim_envs.run_name}/complete_sim_envs # input path for generated simulation environments
  post_path: ${scratch_root}/simulation_environment_datasets/scenario_dreamer_${dataset_name.name}_${postprocess_sim_envs.route_length}m_pickles # output path for post-processed simulation environments
  route_length: 200 # route length for post-processing
  max_num_envs: -1 # if -1, process all environments, otherwise process only the first max_num_envs environments

convert_pickles_to_jsons:
  directory: scenario_dreamer_waymo_200m # directory name of the simulation environments
  path_to_pickles: ${scratch_root}/simulation_environment_datasets/${convert_pickles_to_jsons.directory}_pickles # path to set of simulation environments
  path_to_jsons: ${scratch_root}/simulation_environment_datasets/${convert_pickles_to_jsons.directory}_jsons # path to the json files
  dataset_size: 250 # number of simulation environments to convert

model_name: autoencoder # or ldm or ctrl_sim

# hacky way to not have to manually change the dataset name in all config groups from command line
# only dataset_name has to be configured from command line 
# we have to define this as a group because Hydra resolves the defaults-list before it finishes building the root config
# e.g. `python train.py dataset_name=waymo model_name=autoencoder`
defaults:
  - dataset_name: waymo 
  - dataset@ae.dataset:    ${dataset_name}_autoencoder
  - train@ae.train:      ${dataset_name}_autoencoder
  - eval@ae.eval:       ${dataset_name}_autoencoder
  - model@ae.model:      ${dataset_name}_autoencoder
  - datamodule@ae.datamodule: ${dataset_name}_autoencoder
  - dataset@ldm.dataset:    ${dataset_name}_ldm
  - train@ldm.train:      ${dataset_name}_ldm
  - eval@ldm.eval:       ${dataset_name}_ldm
  - model@ldm.model:      ${dataset_name}_ldm
  - datamodule@ldm.datamodule: ${dataset_name}_ldm
  - dataset@ctrl_sim.dataset:   ${dataset_name}_ctrl_sim
  - train@ctrl_sim.train:      ${dataset_name}_ctrl_sim
  - model@ctrl_sim.model:      ${dataset_name}_ctrl_sim
  - datamodule@ctrl_sim.datamodule: ${dataset_name}_ctrl_sim
  - sim: base